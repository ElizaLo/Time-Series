{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Evaluating decomposed predictions by Orbit (**O**bject-**OR**iented **B**ayes**I**an **T**ime Series)\n",
    "\n",
    "- [Orbit: A Python Package for Bayesian Forecasting](https://github.com/uber/orbit/tree/master)\n",
    "- [Orbitâ€™s Documentation](https://orbit-ml.readthedocs.io/en/stable/)\n",
    "- [Quick Start](https://orbit-ml.readthedocs.io/en/stable/tutorials/quick_start.html#)\n",
    "- [Orbit: Probabilistic Forecast with Exponential Smoothing](https://arxiv.org/abs/2004.08492) Paper\n",
    "\n",
    "\n",
    "### Implemented Models\n",
    "\n",
    "- ETS (which stands for Error, Trend, and Seasonality) Model\n",
    "- Methods of Estimations\n",
    "    - Maximum a Posteriori (MAP)\n",
    "    - Full Bayesian Estimation\n",
    "    - Aggregated Posteriors\n",
    "- Damped Local Trend (DLT)\n",
    "    - Global Trend Configurations:\n",
    "        - Linear Global Trend\n",
    "        - Log-Linear Global Trend\n",
    "        - Flat Global Trend\n",
    "        - Logistic Global Trend\n",
    "    - Damped Local Trend Full Bayesian Estimation (DLTFull)\n",
    "- Local Global Trend (LGT)\n",
    "    - Local Global Trend Maximum a Posteriori (LGTMAP)\n",
    "    - Local Global Trend for full Bayesian prediction (LGTFull)\n",
    "    - Local Global Trend for aggregated posterior prediction (LGTAggregated)\n",
    "- Using Pyro for Estimation\n",
    "    - MAP Fit and Predict\n",
    "    - VI Fit and Predict\n",
    "- Kernel-based Time-varying Regression (KTR)\n",
    "    - Kernel-based Time-varying Regression Lite (KTRLite)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "!pip install awswrangler"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "!pip install orbit-ml --no-input"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import awswrangler as wr\n",
    "import boto3\n",
    "from sagemaker import get_execution_role\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import orbit\n",
    "from orbit import *\n",
    "from orbit.models.dlt import ETSFull, ETSMAP, ETSAggregated, DLTMAP, DLTFull, DLTMAP, DLTAggregated\n",
    "from orbit.models.lgt import LGTMAP, LGTAggregated, LGTFull\n",
    "from orbit.models.ktrlite import KTRLiteMAP\n",
    "\n",
    "from orbit.estimators.pyro_estimator import PyroEstimatorVI, PyroEstimatorMAP"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import warnings\n",
    "\n",
    "warnings.simplefilter('ignore')\n",
    "warnings.filterwarnings('ignore')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Uploading data\n",
    "\n",
    "- uploading data for **models**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "role = get_execution_role()\n",
    "bucket='...'\n",
    "data_key = '...csv' \n",
    "data_location = 's3://{}/{}'.format(bucket, data_key)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df = pd.DataFrame(pd.read_csv(data_location))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df = df.rename({'Unnamed: 0': 'Date'}, axis = 1)\n",
    "df.index = df['Date']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df.shape"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "curve_df = df.drop(['curve'], axis = 0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Orbit Models"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# ETS (which stands for Error, Trend, and Seasonality)\n",
    "\n",
    "# Methods of Estimations\n",
    "\n",
    "# Maximum a Posteriori (MAP)\n",
    "\n",
    "# The advantage of MAP estimation is a faster computational speed.\n",
    "\n",
    "def ETSMAP_model(date_col, response_col, train_df, test_df):\n",
    "    ets = ETSMAP(\n",
    "        response_col=response_col,\n",
    "        date_col=date_col,\n",
    "        seasonality=52,\n",
    "        seed=8888,\n",
    "    )\n",
    "    \n",
    "    ets.fit(df=train_df)\n",
    "    predicted_df_MAP = ets.predict(df=test_df)\n",
    "    \n",
    "    return predicted_df_MAP['prediction'][:11]\n",
    "\n",
    "# Full Bayesian Estimation\n",
    "\n",
    "\n",
    "def ETSFull_model(date_col, response_col, train_df, test_df):\n",
    "    ets = ETSFull(\n",
    "        response_col=response_col,\n",
    "        date_col=date_col,\n",
    "        seasonality=52,\n",
    "        seed=8888,\n",
    "        num_warmup=400,\n",
    "        num_sample=400,\n",
    "    )\n",
    "    \n",
    "    ets.fit(df=train_df)\n",
    "    predicted_df_ETSFull = ets.predict(df=test_df)\n",
    "    \n",
    "    return predicted_df_ETSFull['prediction'][:11]\n",
    "\n",
    "# Aggregated Posteriors\n",
    "\n",
    "def ETSAggregated_model(date_col, response_col, train_df, test_df):\n",
    "    ets = ETSAggregated(\n",
    "        response_col=response_col,\n",
    "        date_col=date_col,\n",
    "        seasonality=52,\n",
    "        seed=8888,\n",
    "    )\n",
    "    ets.fit(df=train_df)\n",
    "    predicted_df_ETSAggregated = ets.predict(df=test_df)\n",
    "    \n",
    "    return predicted_df_ETSAggregated['prediction'][:11]\n",
    "\n",
    "\n",
    "# Damped Local Trend (DLT)\n",
    "\n",
    "# Global Trend Configurations\n",
    "\n",
    "# Linear Global Trend\n",
    "\n",
    "# linear global trend\n",
    "def DLTMAP_lin(date_col, response_col, train_df, test_df):\n",
    "    dlt = DLTMAP(\n",
    "        response_col=response_col,\n",
    "        date_col=date_col,\n",
    "        seasonality=52,\n",
    "        seed=8888,\n",
    "    )\n",
    "\n",
    "    dlt.fit(train_df)\n",
    "    predicted_df_DLTMAP_lin = dlt.predict(test_df)\n",
    "    \n",
    "    return predicted_df_DLTMAP_lin['prediction'][:11]\n",
    "\n",
    "\n",
    "# log-linear global trend\n",
    "def DLTMAP_log_lin(date_col, response_col, train_df, test_df):\n",
    "    dlt = DLTMAP(\n",
    "        response_col=response_col,\n",
    "        date_col=date_col,\n",
    "        seasonality=52,\n",
    "        seed=8888,\n",
    "        global_trend_option='loglinear'\n",
    "    )\n",
    "\n",
    "    dlt.fit(train_df)\n",
    "    predicted_df_DLTMAP_log_lin = dlt.predict(test_df)\n",
    "    \n",
    "    return predicted_df_DLTMAP_log_lin['prediction'][:11]\n",
    "\n",
    "\n",
    "# log-linear global trend\n",
    "def DLTMAP_flat(date_col, response_col, train_df, test_df):\n",
    "    dlt = DLTMAP(\n",
    "        response_col=response_col,\n",
    "        date_col=date_col,\n",
    "        seasonality=52,\n",
    "        seed=8888,\n",
    "        global_trend_option='flat'\n",
    "    )\n",
    "\n",
    "    dlt.fit(train_df)\n",
    "    predicted_df_DLTMAP_flat = dlt.predict(test_df)\n",
    "    \n",
    "    return predicted_df_DLTMAP_flat['prediction'][:11]\n",
    "\n",
    "\n",
    "# logistic global trend\n",
    "def DLTMAP_logistic(date_col, response_col, train_df, test_df):\n",
    "    dlt = DLTMAP(\n",
    "        response_col=response_col,\n",
    "        date_col=date_col,\n",
    "        seasonality=52,\n",
    "        seed=8888,\n",
    "        global_trend_option='logistic'\n",
    "    )\n",
    "\n",
    "    dlt.fit(train_df)\n",
    "    predicted_df_DLTMAP_logistic = dlt.predict(test_df)\n",
    "    \n",
    "    return predicted_df_DLTMAP_logistic['prediction'][:11]\n",
    "\n",
    "\n",
    "# Damped Local Trend Full Bayesian Estimation (DLTFull)\n",
    "\n",
    "def DLTFull_model(date_col, response_col, train_df, test_df):\n",
    "    dlt = DLTFull(\n",
    "        response_col=response_col,\n",
    "        date_col=date_col,\n",
    "        num_warmup=400,\n",
    "        num_sample=400,\n",
    "        seasonality=52,\n",
    "        seed=8888\n",
    "    )\n",
    "    \n",
    "    dlt.fit(df=train_df)\n",
    "    predicted_df_DLTFull = dlt.predict(df=test_df)\n",
    "\n",
    "    return predicted_df_DLTFull['prediction'][:11]\n",
    "\n",
    "\n",
    "# Damped Local Trend Full (DLTAggregated)\n",
    "\n",
    "def DLTAggregated_model(date_col, response_col, train_df, test_df):\n",
    "    ets = DLTAggregated(\n",
    "        response_col=response_col,\n",
    "        date_col=date_col,\n",
    "        seasonality=52,\n",
    "        seed=8888,\n",
    "    )\n",
    "    \n",
    "    ets.fit(df=train_df)\n",
    "    predicted_df_DLTAggregated = ets.predict(df=test_df)\n",
    "    \n",
    "    return predicted_df_DLTAggregated['prediction'][:11]\n",
    "\n",
    "\n",
    "# Local Global Trend (LGT) Model\n",
    "\n",
    "# Local Global Trend Maximum a Posteriori (LGTMAP)\n",
    "\n",
    "def LGTMAP_model(date_col, response_col, train_df, test_df):\n",
    "    lgt = LGTMAP(\n",
    "        response_col=response_col,\n",
    "        date_col=date_col,\n",
    "        seasonality=52,\n",
    "        seed=8888,\n",
    "    )\n",
    "\n",
    "    lgt.fit(df=train_df)\n",
    "    predicted_df_LGTMAP = lgt.predict(df=test_df)\n",
    "    \n",
    "    return predicted_df_LGTMAP['prediction'][:11]\n",
    "\n",
    "# LGTFull\n",
    "\n",
    "def LGTFull_model(date_col, response_col, train_df, test_df):\n",
    "    lgt = LGTFull(\n",
    "        response_col=response_col,\n",
    "        date_col=date_col,\n",
    "        seasonality=52,\n",
    "        seed=8888,\n",
    "    )\n",
    "\n",
    "    lgt.fit(df=train_df)\n",
    "    predicted_df_LGTFull = lgt.predict(df=test_df)\n",
    "    \n",
    "    return predicted_df_LGTFull['prediction'][:11]\n",
    "\n",
    "# LGTAggregated\n",
    "\n",
    "def LGTAggregated_model(date_col, response_col, train_df, test_df):\n",
    "    lgt = LGTAggregated(\n",
    "        response_col=response_col,\n",
    "        date_col=date_col,\n",
    "        seasonality=52,\n",
    "        seed=8888,\n",
    "    )\n",
    "\n",
    "    lgt.fit(df=train_df)\n",
    "    predicted_df_LGTAggregated = lgt.predict(df=test_df)\n",
    "    \n",
    "    return predicted_df_LGTAggregated['prediction'][:11]\n",
    "\n",
    "# Using Pyro for Estimation\n",
    "\n",
    "# MAP Fit and Predict\n",
    "\n",
    "def LGTMAP_PyroEstimatorMAP(date_col, response_col, train_df, test_df):\n",
    "    lgt_map = LGTMAP(\n",
    "        response_col=response_col,\n",
    "        date_col=date_col,\n",
    "        seasonality=52,\n",
    "        seed=8888,\n",
    "        estimator_type=PyroEstimatorMAP,\n",
    "    )\n",
    "\n",
    "    lgt_map.fit(df=train_df)\n",
    "    predicted_df_LGTMAP_pyro = lgt_map.predict(df=test_df)\n",
    "    \n",
    "    return predicted_df_LGTMAP_pyro['prediction'][:11]\n",
    "\n",
    "# VI Fit and Predict\n",
    "\n",
    "def LGTFull_pyro(date_col, response_col, train_df, test_df):\n",
    "    lgt_vi = LGTFull(\n",
    "        response_col=response_col,\n",
    "        date_col=date_col,\n",
    "        seasonality=52,\n",
    "        seed=8888,\n",
    "        num_steps=101,\n",
    "        num_sample=100,\n",
    "        learning_rate=0.1,\n",
    "        n_bootstrap_draws=-1,\n",
    "        estimator_type=PyroEstimatorVI,\n",
    "    )\n",
    "\n",
    "    lgt_vi.fit(df=train_df)\n",
    "\n",
    "    predicted_df_LGTFull_pyro = lgt_vi.predict(df=test_df)\n",
    "    \n",
    "    return predicted_df_LGTFull_pyro['prediction'][:11]\n",
    "\n",
    "\n",
    "# Kernel-based Time-varying Regression (KTR)\n",
    "\n",
    "# KTRLite\n",
    "\n",
    "def ktrlite_MAP(date_col, response_col, train_df, test_df):\n",
    "    ktrlite = KTRLiteMAP(\n",
    "        response_col=response_col,\n",
    "        #response_col=np.log(df[response_col]),\n",
    "        date_col=date_col,\n",
    "        level_knot_scale=.1,\n",
    "        span_level=.05,\n",
    "    )\n",
    "    \n",
    "    ktrlite.fit(train_df)\n",
    "    \n",
    "    predicted_df_ktrlite_MAP = ktrlite.predict(df=test_df, decompose=True)\n",
    "    \n",
    "    return predicted_df_ktrlite_MAP['prediction'][:11]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Root-Mean-Square Deviation (RMSD) or Root-Mean-Square Error (RMSE)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def rmse(actual, pred): \n",
    "    actual, pred = np.array(actual), np.array(pred)\n",
    "    return np.sqrt(np.square(np.subtract(actual,pred)).mean())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def evaluating_models(index, column):\n",
    "    \n",
    "    '''\n",
    "    Parameters:\n",
    "        index: column index\n",
    "        column: column name\n",
    "    \n",
    "    Returns:\n",
    "        models_df: new dataframe with \n",
    "    '''\n",
    "    \n",
    "    tmp_df['Date'] = pd.to_datetime(curve_df['Date'].astype(str))\n",
    "    tmp_df['Penetration'] = curve_df[column].astype(float)\n",
    "    \n",
    "    date_col = 'Date'\n",
    "    response_col = 'Penetration'\n",
    "    \n",
    "\n",
    "    # Decompose Prediction\n",
    "\n",
    "    train_df = tmp_df[tmp_df['Date'] < '2022-01-01']\n",
    "    test_df = tmp_df[tmp_df['Date'] <= '2025-01-01']\n",
    "    \n",
    "    models_df.at[index ,'Item Name'] = column\n",
    "\n",
    "    \n",
    "    # Making predictions with each model\n",
    "    try:\n",
    "        models_df.at[index , 'ETSMAP'] = rmse(\n",
    "            tmp_df['Penetration'][:11], \n",
    "            (ETSMAP_model(date_col, response_col, train_df, test_df))).astype(float)\n",
    "    except:\n",
    "        models_df.at[index , 'ETSMAP'] = 100\n",
    "    try:    \n",
    "        models_df.at[index , 'ETSFull'] = rmse(\n",
    "            tmp_df['Penetration'][:11], \n",
    "            (ETSFull_model(date_col, response_col, train_df, test_df))).astype(float)\n",
    "    except:\n",
    "        models_df.at[index , 'ETSFull'] = 100\n",
    "    try:\n",
    "        models_df.at[index , 'ETSAggregated'] = rmse(\n",
    "            tmp_df['Penetration'][:11], \n",
    "            (ETSAggregated_model(date_col, response_col, train_df, test_df))).astype(float)\n",
    "    except:\n",
    "        models_df.at[index , 'ETSAggregated'] = 100\n",
    "\n",
    "    \n",
    "    try:\n",
    "        models_df.at[index , 'DLTMAP_lin'] = rmse(\n",
    "            tmp_df['Penetration'][:11], \n",
    "            (DLTMAP_lin(date_col, response_col, train_df, test_df))).astype(float)\n",
    "    except:\n",
    "        models_df.at[index , 'DLTMAP_lin'] = 100\n",
    "    try:\n",
    "        models_df.at[index , 'DLTMAP_log_lin'] = rmse(\n",
    "            tmp_df['Penetration'][:11], \n",
    "            (DLTMAP_log_lin(date_col, response_col, train_df, test_df))).astype(float)\n",
    "    except:\n",
    "        models_df.at[index , 'DLTMAP_log_lin'] = 100\n",
    "    try:\n",
    "        models_df.at[index , 'DLTMAP_flat'] = rmse(\n",
    "            tmp_df['Penetration'][:11], \n",
    "            (DLTMAP_flat(date_col, response_col, train_df, test_df))).astype(float)\n",
    "    except:\n",
    "        models_df.at[index , 'DLTMAP_flat'] = 100\n",
    "    try:\n",
    "        models_df.at[index , 'DLTMAP_logistic'] = rmse(\n",
    "            tmp_df['Penetration'][:11], \n",
    "            (DLTMAP_logistic(date_col, response_col, train_df, test_df))).astype(float)\n",
    "    except:\n",
    "        models_df.at[index , 'DLTMAP_logistic'] = 100\n",
    "    try:    \n",
    "        models_df.at[index , 'DLTFull'] = rmse(\n",
    "            tmp_df['Penetration'][:11], \n",
    "            (DLTFull_model(date_col, response_col, train_df, test_df))).astype(float)\n",
    "    except:\n",
    "        models_df.at[index , 'DLTFull'] = 100\n",
    "    try:\n",
    "        models_df.at[index , 'DLTAggregated'] = rmse(\n",
    "            tmp_df['Penetration'][:11], \n",
    "            (DLTAggregated_model(date_col, response_col, train_df, test_df))).astype(float)\n",
    "    except:  \n",
    "        models_df.at[index , 'DLTAggregated'] = 100\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        models_df.at[index , 'LGTMAP'] = rmse(\n",
    "            tmp_df['Penetration'][:11], \n",
    "            (LGTMAP_model(date_col, response_col, train_df, test_df))).astype(float)\n",
    "    except:\n",
    "        models_df.at[index , 'LGTMAP'] = 100\n",
    "    try:\n",
    "        models_df.at[index , 'LGTFull'] = rmse(\n",
    "            tmp_df['Penetration'][:11], \n",
    "            (LGTFull_model(date_col, response_col, train_df, test_df))).astype(float)\n",
    "    except: \n",
    "        models_df.at[index , 'LGTFull'] = 100\n",
    "    try: \n",
    "        models_df.at[index , 'LGTAggregated'] = rmse(\n",
    "            tmp_df['Penetration'][:11], \n",
    "            (LGTAggregated_model(date_col, response_col, train_df, test_df))).astype(float)\n",
    "    except:\n",
    "        models_df.at[index , 'LGTAggregated'] = 100\n",
    "\n",
    "    \n",
    "    # Using Pyro for Estimation\n",
    "    try:\n",
    "        models_df.at[index , 'LGTMAP_PyroEstimatorMAP'] = rmse(\n",
    "            tmp_df['Penetration'][:11], (LGTMAP_PyroEstimatorMAP(date_col, \n",
    "                                                    response_col, train_df, test_df))).astype(float)\n",
    "    except:\n",
    "        models_df.at[index , 'LGTMAP_PyroEstimatorMAP'] = 100\n",
    "    try:\n",
    "        models_df.at[index , 'LGTFull_pyro4'] = rmse(\n",
    "            tmp_df['Penetration'][:11], \n",
    "            (LGTFull_pyro(date_col, response_col, train_df, test_df))).astype(float)\n",
    "    except:\n",
    "         models_df.at[index , 'LGTFull_pyro4'] = 100\n",
    "        \n",
    "    # Kernel-based Time-varying Regression (KTR)\n",
    "    try:\n",
    "        models_df.at[index , 'KTR_Lite_MAP'] = rmse(\n",
    "            tmp_df['Penetration'][:11], \n",
    "            (ktrlite_MAP(date_col, response_col, train_df, test_df))).astype(float)\n",
    "    except:\n",
    "        models_df.at[index , 'KTR_Lite_MAP'] = 100\n",
    "    \n",
    "    \n",
    "    models_df.at[index, 'Curve Type'] = df[column].iloc[-1]\n",
    "        \n",
    "        \n",
    "    return models_df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Calculating minimal RMSE value for each item"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def min_value(df):\n",
    "    \n",
    "    '''\n",
    "    Parameters:\n",
    "        df: input dataframe with multiple columns and values in a row\n",
    "    \n",
    "    Returns:\n",
    "        models_df: existing dataframe with added the new 'Model' column filled with \n",
    "        the name of the best-fitted model for each item\n",
    "    '''\n",
    "        \n",
    "    df.iloc[:, 1:-1].apply(pd.to_numeric)\n",
    "    df['Model'] = df.iloc[:, 1:-1].idxmin(axis=1)\n",
    "    \n",
    "    return models_df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluating Orbit models for each item"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import time\n",
    "\n",
    "\n",
    "tmp_df = pd.DataFrame()\n",
    "models_df = pd.DataFrame()\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for index, column in enumerate(curve_df.columns[1:2]):\n",
    "    evaluating_models(index, column)\n",
    "    \n",
    "end = time.time()\n",
    "print(end - start)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "models_df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "min_value(models_df)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "instance_type": "ml.g4dn.xlarge",
  "kernelspec": {
   "display_name": "Python 3 (PyTorch 1.6 Python 3.6 GPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/pytorch-1.6-gpu-py36-cu110-ubuntu18.04-v3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
