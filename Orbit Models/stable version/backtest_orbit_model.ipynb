{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backtest Orbit Model\n",
    "\n",
    "- [Orbit: A Python Package for Bayesian Forecasting](https://github.com/uber/orbit)\n",
    "- [Orbitâ€™s Documentation](https://orbit-ml.readthedocs.io/en/stable/index.html)\n",
    "- [Quick Start](https://orbit-ml.readthedocs.io/en/stable/tutorials/quick_start.html)\n",
    "- [Orbit: Probabilistic Forecast with Exponential Smoothing](https://arxiv.org/abs/2004.08492) Paper\n",
    "- [Backtest Orbit Model Documentation](https://orbit-ml.readthedocs.io/en/stable/tutorials/backtest.html)\n",
    "\n",
    "\n",
    "## Backtest\n",
    "\n",
    "The way to gauge the performance of a time-series model is through re-training models with different historic periods and check their forecast within certain steps. This is similar to a time-based style cross-validation. More often, we called it `backtest` in time-series modeling.\n",
    "\n",
    "Two schemes supported for the back-testing engine: **expanding window** and **rolling window**.\n",
    "\n",
    "### Implemented Models\n",
    "\n",
    "- ETS (which stands for Error, Trend, and Seasonality) Model\n",
    "- Methods of Estimations\n",
    "    - Maximum a Posteriori (MAP)\n",
    "    - Full Bayesian Estimation\n",
    "    - Aggregated Posteriors\n",
    "- Damped Local Trend (DLT)\n",
    "    - Global Trend Configurations:\n",
    "        - Linear Global Trend\n",
    "        - Log-Linear Global Trend\n",
    "        - Flat Global Trend\n",
    "        - Logistic Global Trend\n",
    "    - Damped Local Trend Full Bayesian Estimation (DLTFull)\n",
    "- Local Global Trend (LGT)\n",
    "    - Local Global Trend Maximum a Posteriori (LGTMAP)\n",
    "    - Local Global Trend for full Bayesian prediction (LGTFull)\n",
    "    - Local Global Trend for aggregated posterior prediction (LGTAggregated)\n",
    "- Using Pyro for Estimation\n",
    "    - MAP Fit and Predict\n",
    "    - VI Fit and Predict\n",
    "- Kernel-based Time-varying Regression (KTR)\n",
    "    - Kernel-based Time-varying Regression Lite (KTRLite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install orbit-ml==1.0.17 --upgrade --no-input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import boto3\n",
    "from sagemaker import get_execution_role\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "import orbit\n",
    "from orbit.models.dlt import ETSFull, ETSMAP, ETSAggregated, DLTMAP, DLTFull, DLTMAP, DLTAggregated\n",
    "from orbit.models.lgt import LGTMAP, LGTAggregated, LGTFull\n",
    "from orbit.models.ktrlite import KTRLiteMAP\n",
    "from orbit.estimators.pyro_estimator import PyroEstimatorVI, PyroEstimatorMAP\n",
    "from orbit.diagnostics.backtest import BackTester, TimeSeriesSplitter\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(orbit.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "role = get_execution_role()\n",
    "bucket='...'\n",
    "data_key = '...'\n",
    "data_location = 's3://{}/{}'.format(bucket, data_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(pd.read_csv(data_location))\n",
    "df = df.drop(df.index[11:]) #drop to forecast for N years only\n",
    "df['Date'] = pd.to_datetime(df['Date'].astype(str))\n",
    "df['Value'] = df['Value'].astype(float)\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_col = 'Date'\n",
    "response_col = 'Value'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a TimeSeriesSplitter\n",
    "\n",
    "### Expanding window\n",
    "\n",
    "- **expanding window:** for each back-testing model training, the train start date is fixed, while the train end date is extended forward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configs\n",
    "min_train_len = 4 # minimal length of window length\n",
    "forecast_len = 2 # length forecast window\n",
    "incremental_len = 1 # step length for moving forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configs\n",
    "min_train_len = 5 # in case of rolling window, this specify the length of window length\n",
    "forecast_len = 1 # length forecast window\n",
    "incremental_len = 1 # step length for moving forward\n",
    "window_type = 'expanding' # 'rolling'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_splitter = TimeSeriesSplitter(df,\n",
    "                                  min_train_len=min_train_len,\n",
    "                                  incremental_len=incremental_len,\n",
    "                                  forecast_len=forecast_len,\n",
    "                                  window_type='expanding', \n",
    "                                  date_col='Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ex_splitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = ex_splitter.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a BackTester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate a model\n",
    "dlt = DLTMAP(\n",
    "    date_col='Date',\n",
    "    response_col='Value'\n",
    ")\n",
    "\n",
    "lgt_vi = LGTFull(\n",
    "    response_col='Value',\n",
    "    date_col='Date',\n",
    "    seasonality=52,\n",
    "    seed=8888,\n",
    "    num_steps=101,\n",
    "    num_sample=100,\n",
    "    learning_rate=0.1,\n",
    "    n_bootstrap_draws=-1,\n",
    "    estimator_type=PyroEstimatorVI,\n",
    ")\n",
    "\n",
    "etsMAP_model = ETSMAP(\n",
    "        response_col='Value',\n",
    "        date_col='Date',\n",
    "        seasonality=52,\n",
    "        seed=8888,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configs\n",
    "min_train_len = 3\n",
    "forecast_len = 1\n",
    "incremental_len = 1\n",
    "window_type = 'expanding'\n",
    "\n",
    "bt = BackTester(\n",
    "    model=etsMAP_model,\n",
    "    df=df,\n",
    "    min_train_len=min_train_len,\n",
    "    incremental_len=incremental_len,\n",
    "    forecast_len=forecast_len,\n",
    "    window_type=window_type,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backtest fit and predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bt.fit_predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_df = bt.get_predicted_df()\n",
    "predicted_df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_df.loc[predicted_df['training_data'] == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(bt.score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = bt.score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_naive(test_actual):\n",
    "    actual = test_actual[1:]\n",
    "    predicted = test_actual[:-1]\n",
    "    return np.mean(np.square(actual - predicted))\n",
    "\n",
    "def naive_error(train_actual, test_predicted):\n",
    "    train_mean = np.mean(train_actual)\n",
    "    return np.mean(np.abs(test_predicted - train_mean))\n",
    "\n",
    "def rmse(train_actual, test_predicted):\n",
    "    print(train_actual[-7:])\n",
    "    print(test_predicted)\n",
    "    return np.sqrt(np.square(np.subtract(train_actual[-7:],test_predicted[:-1])).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bt.score(metrics=[rmse])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \n",
    "\n",
    "-------------------------\n",
    "\n",
    "## Backtesting\n",
    "\n",
    "### Expanding Window\n",
    "\n",
    "> for each back-testing model training, the train start date is fixed, while the train end date is extended forward.\n",
    "\n",
    "### Rolling Window\n",
    "\n",
    "> for each back-testing model training, the training window length is fixed but the window is moving forward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "role = get_execution_role()\n",
    "bucket='...'\n",
    "data_key = '...' \n",
    "data_location = 's3://{}/{}'.format(bucket, data_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(pd.read_csv(data_location))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename({'Unnamed: 0': 'Date'}, axis = 1)\n",
    "df.index = df['Date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Orbit Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ETS (which stands for Error, Trend, and Seasonality)\n",
    "\n",
    "# Methods of Estimations\n",
    "\n",
    "# Maximum a Posteriori (MAP)\n",
    "\n",
    "# The advantage of MAP estimation is a faster computational speed.\n",
    "\n",
    "def ETSMAP_model(date_col, response_col, tmp_df, \n",
    "                 min_train_len, forecast_len, incremental_len, window_type):\n",
    "    \n",
    "    ets = ETSMAP(\n",
    "        response_col=response_col,\n",
    "        date_col=date_col,\n",
    "        seasonality=52,\n",
    "        seed=8888\n",
    "    )\n",
    "    \n",
    "    bt = BackTester(\n",
    "            model=ets,\n",
    "            df=tmp_df,\n",
    "            min_train_len=min_train_len,\n",
    "            incremental_len=incremental_len,\n",
    "            forecast_len=forecast_len,\n",
    "            window_type=window_type,\n",
    "        )\n",
    "    \n",
    "    bt.fit_predict()\n",
    "    \n",
    "    return bt.score().iloc[5]['metric_values'] # rmsse\n",
    "\n",
    "\n",
    "# Full Bayesian Estimation\n",
    "\n",
    "\n",
    "def ETSFull_model(date_col, response_col, tmp_df, \n",
    "                 min_train_len, forecast_len, incremental_len, window_type):\n",
    "    \n",
    "    ets = ETSFull(\n",
    "        response_col=response_col,\n",
    "        date_col=date_col,\n",
    "        seasonality=52,\n",
    "        seed=8888,\n",
    "        num_warmup=400,\n",
    "        num_sample=400,\n",
    "    )\n",
    "    \n",
    "    bt = BackTester(\n",
    "            model=ets,\n",
    "            df=tmp_df,\n",
    "            min_train_len=min_train_len,\n",
    "            incremental_len=incremental_len,\n",
    "            forecast_len=forecast_len,\n",
    "            window_type=window_type,\n",
    "        )\n",
    "    \n",
    "    bt.fit_predict()\n",
    "    \n",
    "    return bt.score().iloc[5]['metric_values'] # rmsse\n",
    "\n",
    "# Aggregated Posteriors\n",
    "\n",
    "\n",
    "def ETSAggregated_model(date_col, response_col, tmp_df, \n",
    "                        min_train_len, forecast_len, incremental_len, window_type):\n",
    "    \n",
    "    ets = ETSAggregated(\n",
    "        response_col=response_col,\n",
    "        date_col=date_col,\n",
    "        seasonality=52,\n",
    "        seed=8888,\n",
    "    )\n",
    "    \n",
    "    bt = BackTester(\n",
    "            model=ets,\n",
    "            df=tmp_df,\n",
    "            min_train_len=min_train_len,\n",
    "            incremental_len=incremental_len,\n",
    "            forecast_len=forecast_len,\n",
    "            window_type=window_type,\n",
    "        )\n",
    "    \n",
    "    bt.fit_predict()\n",
    "        \n",
    "    return bt.score().iloc[5]['metric_values'] # rmsse\n",
    "\n",
    "\n",
    "# Damped Local Trend (DLT)\n",
    "\n",
    "# Global Trend Configurations\n",
    "\n",
    "# Linear Global Trend\n",
    "\n",
    "# linear global trend\n",
    "def DLTMAP_lin(date_col, response_col, tmp_df, \n",
    "               min_train_len, forecast_len, incremental_len, window_type):\n",
    "    \n",
    "    dlt = DLTMAP(\n",
    "        response_col=response_col,\n",
    "        date_col=date_col,\n",
    "        seasonality=52,\n",
    "        seed=8888,\n",
    "    )\n",
    "\n",
    "    bt = BackTester(\n",
    "            model=dlt,\n",
    "            df=tmp_df,\n",
    "            min_train_len=min_train_len,\n",
    "            incremental_len=incremental_len,\n",
    "            forecast_len=forecast_len,\n",
    "            window_type=window_type,\n",
    "        )\n",
    "    \n",
    "    bt.fit_predict()\n",
    "        \n",
    "    return bt.score().iloc[5]['metric_values'] # rmsse\n",
    "\n",
    "\n",
    "# log-linear global trend\n",
    "def DLTMAP_log_lin(date_col, response_col, tmp_df, \n",
    "                   min_train_len, forecast_len, incremental_len, window_type):\n",
    "    \n",
    "    dlt = DLTMAP(\n",
    "        response_col=response_col,\n",
    "        date_col=date_col,\n",
    "        seasonality=52,\n",
    "        seed=8888,\n",
    "        global_trend_option='loglinear'\n",
    "    )\n",
    "\n",
    "    bt = BackTester(\n",
    "            model=dlt,\n",
    "            df=tmp_df,\n",
    "            min_train_len=min_train_len,\n",
    "            incremental_len=incremental_len,\n",
    "            forecast_len=forecast_len,\n",
    "            window_type=window_type,\n",
    "        )\n",
    "    \n",
    "    bt.fit_predict()\n",
    "        \n",
    "    return bt.score().iloc[5]['metric_values'] # rmsse\n",
    "\n",
    "\n",
    "# log-linear global trend\n",
    "def DLTMAP_flat(date_col, response_col, tmp_df, \n",
    "                min_train_len, forecast_len, incremental_len, window_type):\n",
    "    \n",
    "    dlt = DLTMAP(\n",
    "        response_col=response_col,\n",
    "        date_col=date_col,\n",
    "        seasonality=52,\n",
    "        seed=8888,\n",
    "        global_trend_option='flat'\n",
    "    )\n",
    "\n",
    "    bt = BackTester(\n",
    "            model=dlt,\n",
    "            df=tmp_df,\n",
    "            min_train_len=min_train_len,\n",
    "            incremental_len=incremental_len,\n",
    "            forecast_len=forecast_len,\n",
    "            window_type=window_type,\n",
    "        )\n",
    "    \n",
    "    bt.fit_predict()\n",
    "        \n",
    "    return bt.score().iloc[5]['metric_values'] # rmsse\n",
    "\n",
    "\n",
    "# logistic global trend\n",
    "def DLTMAP_logistic(date_col, response_col, tmp_df, \n",
    "                    min_train_len, forecast_len, incremental_len, window_type):\n",
    "    \n",
    "    dlt = DLTMAP(\n",
    "        response_col=response_col,\n",
    "        date_col=date_col,\n",
    "        seasonality=52,\n",
    "        seed=8888,\n",
    "        global_trend_option='logistic'\n",
    "    )\n",
    "\n",
    "    bt = BackTester(\n",
    "            model=dlt,\n",
    "            df=tmp_df,\n",
    "            min_train_len=min_train_len,\n",
    "            incremental_len=incremental_len,\n",
    "            forecast_len=forecast_len,\n",
    "            window_type=window_type,\n",
    "        )\n",
    "    \n",
    "    bt.fit_predict()\n",
    "    \n",
    "    return bt.score().iloc[5]['metric_values'] # rmsse\n",
    "\n",
    "\n",
    "# Damped Local Trend Full Bayesian Estimation (DLTFull)\n",
    "\n",
    "def DLTFull_model(date_col, response_col, tmp_df, \n",
    "                  min_train_len, forecast_len, incremental_len, window_type):\n",
    "    \n",
    "    dlt = DLTFull(\n",
    "        response_col=response_col,\n",
    "        date_col=date_col,\n",
    "        num_warmup=400,\n",
    "        num_sample=400,\n",
    "        seasonality=52,\n",
    "        seed=8888\n",
    "    )\n",
    "    \n",
    "    bt = BackTester(\n",
    "            model=dlt,\n",
    "            df=tmp_df,\n",
    "            min_train_len=min_train_len,\n",
    "            incremental_len=incremental_len,\n",
    "            forecast_len=forecast_len,\n",
    "            window_type=window_type,\n",
    "        )\n",
    "    \n",
    "    bt.fit_predict()\n",
    "\n",
    "    return bt.score().iloc[5]['metric_values'] # rmsse\n",
    "\n",
    "\n",
    "# Damped Local Trend Full (DLTAggregated)\n",
    "\n",
    "def DLTAggregated_model(date_col, response_col, tmp_df, \n",
    "                        min_train_len, forecast_len, incremental_len, window_type):\n",
    "    \n",
    "    ets = DLTAggregated(\n",
    "        response_col=response_col,\n",
    "        date_col=date_col,\n",
    "        seasonality=52,\n",
    "        seed=8888,\n",
    "    )\n",
    "    \n",
    "    bt = BackTester(\n",
    "            model=ets,\n",
    "            df=tmp_df,\n",
    "            min_train_len=min_train_len,\n",
    "            incremental_len=incremental_len,\n",
    "            forecast_len=forecast_len,\n",
    "            window_type=window_type,\n",
    "        )\n",
    "    \n",
    "    bt.fit_predict()\n",
    "\n",
    "    return bt.score().iloc[5]['metric_values'] # rmsse\n",
    "\n",
    "\n",
    "# Local Global Trend (LGT) Model\n",
    "\n",
    "# Local Global Trend Maximum a Posteriori (LGTMAP)\n",
    "\n",
    "def LGTMAP_model(date_col, response_col, tmp_df, \n",
    "                 min_train_len, forecast_len, incremental_len, window_type):\n",
    "    \n",
    "    lgt = LGTMAP(\n",
    "        response_col=response_col,\n",
    "        date_col=date_col,\n",
    "        seasonality=52,\n",
    "        seed=8888,\n",
    "    )\n",
    "\n",
    "    bt = BackTester(\n",
    "            model=lgt,\n",
    "            df=tmp_df,\n",
    "            min_train_len=min_train_len,\n",
    "            incremental_len=incremental_len,\n",
    "            forecast_len=forecast_len,\n",
    "            window_type=window_type,\n",
    "        )\n",
    "    \n",
    "    bt.fit_predict()\n",
    "\n",
    "    return bt.score().iloc[5]['metric_values'] # rmsse\n",
    "\n",
    "# LGTFull\n",
    "\n",
    "def LGTFull_model(date_col, response_col, tmp_df, \n",
    "                  min_train_len, forecast_len, incremental_len, window_type):\n",
    "    \n",
    "    lgt = LGTFull(\n",
    "        response_col=response_col,\n",
    "        date_col=date_col,\n",
    "        seasonality=52,\n",
    "        seed=8888,\n",
    "    )\n",
    "\n",
    "    bt = BackTester(\n",
    "            model=lgt,\n",
    "            df=tmp_df,\n",
    "            min_train_len=min_train_len,\n",
    "            incremental_len=incremental_len,\n",
    "            forecast_len=forecast_len,\n",
    "            window_type=window_type,\n",
    "        )\n",
    "    \n",
    "    bt.fit_predict()\n",
    "\n",
    "    return bt.score().iloc[5]['metric_values'] # rmsse\n",
    "\n",
    "# LGTAggregated\n",
    "\n",
    "def LGTAggregated_model(date_col, response_col, tmp_df, \n",
    "                        min_train_len, forecast_len, incremental_len, window_type):\n",
    "    \n",
    "    lgt = LGTAggregated(\n",
    "        response_col=response_col,\n",
    "        date_col=date_col,\n",
    "        seasonality=52,\n",
    "        seed=8888,\n",
    "    )\n",
    "\n",
    "    bt = BackTester(\n",
    "            model=lgt,\n",
    "            df=tmp_df,\n",
    "            min_train_len=min_train_len,\n",
    "            incremental_len=incremental_len,\n",
    "            forecast_len=forecast_len,\n",
    "            window_type=window_type,\n",
    "        )\n",
    "    \n",
    "    bt.fit_predict()\n",
    "\n",
    "    return bt.score().iloc[5]['metric_values'] # rmsse\n",
    "\n",
    "# Using Pyro for Estimation\n",
    "\n",
    "# MAP Fit and Predict\n",
    "\n",
    "def LGTMAP_PyroEstimatorMAP(date_col, response_col, tmp_df, \n",
    "                            min_train_len, forecast_len, incremental_len, window_type):\n",
    "    \n",
    "    lgt_map = LGTMAP(\n",
    "        response_col=response_col,\n",
    "        date_col=date_col,\n",
    "        seasonality=52,\n",
    "        seed=8888,\n",
    "        estimator_type=PyroEstimatorMAP,\n",
    "    )\n",
    "\n",
    "    bt = BackTester(\n",
    "            model=lgt_map,\n",
    "            df=tmp_df,\n",
    "            min_train_len=min_train_len,\n",
    "            incremental_len=incremental_len,\n",
    "            forecast_len=forecast_len,\n",
    "            window_type=window_type,\n",
    "        )\n",
    "    \n",
    "    bt.fit_predict()\n",
    "\n",
    "    return bt.score().iloc[5]['metric_values'] # rmsse\n",
    "\n",
    "# VI Fit and Predict\n",
    "\n",
    "def LGTFull_pyro(date_col, response_col, tmp_df, \n",
    "                 min_train_len, forecast_len, incremental_len, window_type):\n",
    "    \n",
    "    lgt_vi = LGTFull(\n",
    "        response_col=response_col,\n",
    "        date_col=date_col,\n",
    "        seasonality=52,\n",
    "        seed=8888,\n",
    "        num_steps=101,\n",
    "        num_sample=100,\n",
    "        learning_rate=0.1,\n",
    "        n_bootstrap_draws=-1,\n",
    "        estimator_type=PyroEstimatorVI,\n",
    "    )\n",
    "\n",
    "    bt = BackTester(\n",
    "            model=lgt_vi,\n",
    "            df=tmp_df,\n",
    "            min_train_len=min_train_len,\n",
    "            incremental_len=incremental_len,\n",
    "            forecast_len=forecast_len,\n",
    "            window_type=window_type,\n",
    "        )\n",
    "    \n",
    "    bt.fit_predict()\n",
    "\n",
    "    return bt.score().iloc[5]['metric_values'] # rmsse\n",
    "\n",
    "\n",
    "# Kernel-based Time-varying Regression (KTR)\n",
    "\n",
    "# KTRLite\n",
    "\n",
    "def ktrlite_MAP(date_col, response_col, tmp_df, \n",
    "                min_train_len, forecast_len, incremental_len, window_type):\n",
    "    \n",
    "    ktrlite = KTRLiteMAP(\n",
    "        response_col=response_col,\n",
    "        #response_col=np.log(df[response_col]),\n",
    "        date_col=date_col,\n",
    "        level_knot_scale=.1,\n",
    "        span_level=.05,\n",
    "    )\n",
    "    \n",
    "    bt = BackTester(\n",
    "            model=ktrlite,\n",
    "            df=tmp_df,\n",
    "            min_train_len=min_train_len,\n",
    "            incremental_len=incremental_len,\n",
    "            forecast_len=forecast_len,\n",
    "            window_type=window_type,\n",
    "        )\n",
    "    \n",
    "    bt.fit_predict()\n",
    "\n",
    "    return bt.score().iloc[5]['metric_values'] # rmsse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Backtest all Orbit models for each item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backtesing_models(index, column):\n",
    "    \n",
    "    '''\n",
    "    Parameters:\n",
    "        index: column index\n",
    "        column: column name\n",
    "    \n",
    "    Returns:\n",
    "        models_df: new dataframe with \n",
    "    '''\n",
    "    \n",
    "    tmp_df['Date'] = pd.to_datetime(df['Date'].astype(str))\n",
    "    tmp_df['Penetration'] = df[column].astype(float)\n",
    "    \n",
    "    date_col = 'Date'\n",
    "    response_col = 'Value'\n",
    "\n",
    "    models_df.at[index ,'Name'] = column\n",
    "\n",
    "    # configs\n",
    "    min_train_len = 5 # in case of rolling window, this specify the length of window length\n",
    "    forecast_len = 1 # length forecast window\n",
    "    incremental_len = 1 # step length for moving forward\n",
    "    window_type = 'expanding' # 'rolling' 'expanding'\n",
    "        \n",
    "    \n",
    "    # Making backtesting with each model\n",
    "    try:\n",
    "        models_df.at[index , 'ETSMAP'] = ETSMAP_model(date_col, response_col, tmp_df, \n",
    "                                                      min_train_len, forecast_len, incremental_len, \n",
    "                                                      window_type)\n",
    "    except:\n",
    "        models_df.at[index , 'ETSMAP'] = 100\n",
    "    try:    \n",
    "        models_df.at[index , 'ETSFull'] = ETSFull_model(date_col, response_col, tmp_df, \n",
    "                                                        min_train_len, forecast_len, incremental_len, \n",
    "                                                        window_type)\n",
    "    except:\n",
    "        models_df.at[index , 'ETSFull'] = 100\n",
    "    try:\n",
    "        models_df.at[index , 'ETSAggregated'] = ETSAggregated_model(date_col, response_col, tmp_df, \n",
    "                                                        min_train_len, forecast_len, incremental_len, \n",
    "                                                        window_type)\n",
    "    except:\n",
    "        models_df.at[index , 'ETSAggregated'] = 100\n",
    "\n",
    "    \n",
    "    try:\n",
    "        models_df.at[index , 'DLTMAP_lin'] = DLTMAP_lin(date_col, response_col, tmp_df, \n",
    "                                                        min_train_len, forecast_len, incremental_len, \n",
    "                                                        window_type)\n",
    "    except:\n",
    "        models_df.at[index , 'DLTMAP_lin'] = 100\n",
    "    try:\n",
    "        models_df.at[index , 'DLTMAP_log_lin'] = DLTMAP_log_lin(date_col, response_col, tmp_df, \n",
    "                                                        min_train_len, forecast_len, incremental_len, \n",
    "                                                        window_type)\n",
    "    except:\n",
    "        models_df.at[index , 'DLTMAP_log_lin'] = 100\n",
    "    try:\n",
    "        models_df.at[index , 'DLTMAP_flat'] = DLTMAP_flat(date_col, response_col, tmp_df, \n",
    "                                                        min_train_len, forecast_len, incremental_len, \n",
    "                                                        window_type)\n",
    "    except:\n",
    "        models_df.at[index , 'DLTMAP_flat'] = 100\n",
    "    try:\n",
    "        models_df.at[index , 'DLTMAP_logistic'] = DLTMAP_logistic(date_col, response_col, tmp_df, \n",
    "                                                        min_train_len, forecast_len, incremental_len, \n",
    "                                                        window_type)\n",
    "    except:\n",
    "        models_df.at[index , 'DLTMAP_logistic'] = 100\n",
    "    try:    \n",
    "        models_df.at[index , 'DLTFull'] = DLTFull_model(date_col, response_col, tmp_df, \n",
    "                                                        min_train_len, forecast_len, incremental_len, \n",
    "                                                        window_type)\n",
    "    except:\n",
    "        models_df.at[index , 'DLTFull'] = 100\n",
    "    try:\n",
    "        models_df.at[index , 'DLTAggregated'] = DLTAggregated_model(date_col, response_col, tmp_df, \n",
    "                                                        min_train_len, forecast_len, incremental_len, \n",
    "                                                        window_type)\n",
    "    except:  \n",
    "        models_df.at[index , 'DLTAggregated'] = 100\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        models_df.at[index , 'LGTMAP'] = LGTMAP_model(date_col, response_col, tmp_df, \n",
    "                                                        min_train_len, forecast_len, incremental_len, \n",
    "                                                        window_type)\n",
    "    except:\n",
    "        models_df.at[index , 'LGTMAP'] = 100\n",
    "    try:\n",
    "        models_df.at[index , 'LGTFull'] = LGTFull_model(date_col, response_col, tmp_df, \n",
    "                                                        min_train_len, forecast_len, incremental_len, \n",
    "                                                        window_type)\n",
    "    except: \n",
    "        models_df.at[index , 'LGTFull'] = 100\n",
    "    try: \n",
    "        models_df.at[index , 'LGTAggregated'] = LGTAggregated_model(date_col, response_col, tmp_df, \n",
    "                                                        min_train_len, forecast_len, incremental_len, \n",
    "                                                        window_type)\n",
    "    except:\n",
    "        models_df.at[index , 'LGTAggregated'] = 100\n",
    "\n",
    "    \n",
    "    # Using Pyro for Estimation\n",
    "    try:\n",
    "        models_df.at[index , 'LGTMAP_PyroEstimatorMAP'] = LGTMAP_PyroEstimatorMAP(\n",
    "            date_col, response_col, tmp_df, min_train_len, forecast_len, incremental_len, window_type)\n",
    "    except:\n",
    "        models_df.at[index , 'LGTMAP_PyroEstimatorMAP'] = 100\n",
    "    try:\n",
    "        models_df.at[index , 'LGTFull_pyro4'] = LGTFull_pyro(date_col, response_col, tmp_df, \n",
    "                                                        min_train_len, forecast_len, incremental_len, \n",
    "                                                        window_type)\n",
    "    except:\n",
    "         models_df.at[index , 'LGTFull_pyro4'] = 100\n",
    "        \n",
    "    # Kernel-based Time-varying Regression (KTR)\n",
    "    try:\n",
    "        models_df.at[index , 'KTR_Lite_MAP'] = ktrlite_MAP(date_col, response_col, tmp_df, \n",
    "                                                        min_train_len, forecast_len, incremental_len, \n",
    "                                                        window_type)\n",
    "    except:\n",
    "        models_df.at[index , 'KTR_Lite_MAP'] = 100\n",
    "    \n",
    "    \n",
    "    models_df.at[index, 'Type'] = df[column].iloc[-1]\n",
    "    \n",
    "        \n",
    "    return models_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculating minimal RMSSE value for each item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_value(df):\n",
    "    \n",
    "    '''\n",
    "    Parameters:\n",
    "        df: input dataframe with multiple columns and values in a row\n",
    "    \n",
    "    Returns:\n",
    "        models_df: existing dataframe with added the new 'Model' column filled with \n",
    "        the name of the best-fitted model for each item\n",
    "    '''\n",
    "        \n",
    "    df.iloc[:, 1:-1].apply(pd.to_numeric)\n",
    "    df['Model'] = df.iloc[:, 1:-1].idxmin(axis=1)\n",
    "    \n",
    "    return models_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Backtest Orbit models for each item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "tmp_df = pd.DataFrame()\n",
    "models_df = pd.DataFrame()\n",
    "\n",
    "#start = time.time()\n",
    "\n",
    "for index, column in enumerate(df.columns[1:2]):\n",
    "    evaluating_models(index, column)\n",
    "    \n",
    "#end = time.time()\n",
    "#print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_value(models_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.g4dn.xlarge",
  "kernelspec": {
   "display_name": "Python 3 (PyTorch 1.6 Python 3.6 GPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/pytorch-1.6-gpu-py36-cu110-ubuntu18.04-v3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
